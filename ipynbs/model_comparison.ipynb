{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./../src/')\n",
    "\n",
    "import os\n",
    "import utils\n",
    "import ioutil\n",
    "import feature_selection\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from model_comparison import model_comparison\n",
    "from model_selection import nested_cross_val\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time budget**\n",
    "* 18 filters + 25 discr combos = 450 experiments\n",
    "* Each experiemnt comprises:\n",
    "    - M models (2/3)\n",
    "    - 6 feature selection algs \n",
    "    - (20/30/40) repetitions\n",
    "    - 4 folds\n",
    "\n",
    "- C1: 20 CPUs\n",
    "- C2: 8 CPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48600.0, 81000.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of required runs to complete \n",
    "nruns_comp1 = 18 * 25 * 3 * 6 * 20 * 4 / 20\n",
    "nruns_comp2 = 18 * 25 * 2 * 6 * 20 * 4 / 8\n",
    "\n",
    "nruns_comp1, nruns_comp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.4375, 14.0625)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Amount of time at disposal (min)\n",
    "avail_time = 60 * 24 * 4\n",
    "\n",
    "min_per_C1runs = nruns_comp1 / avail_time\n",
    "min_per_C2runs = nruns_comp2 / avail_time\n",
    "# Required number of runs per minute\n",
    "min_per_C1runs, min_per_C2runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_auc_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ef1f97aa868f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mSCORE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mPENALTY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'l1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'l2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'roc_auc_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Setup:\n",
    "K, CV, SEED = 20, 4, 0\n",
    "\n",
    "# Priors summing to 1.0.\n",
    "PFS_PRIORS = [0.677, 0.323]\n",
    "LRC_PRIORS = [0.753, 0.247]\n",
    "\n",
    "MAX_ITER = [800]\n",
    "\n",
    "N_ESTIMATORS = [20, 50, 100, 200, 500, 1000]\n",
    "LEARNINGR_RATE = [0.001, 0.05, 0.2, 0.6, 1, 3]\n",
    "\n",
    "TOL = [0.0001, 0.001, 0.01, 0.1, 0.3, 0.7, 1]\n",
    "C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "SCORE = roc_auc_score\n",
    "\n",
    "PENALTY = ['l1', 'l2']\n",
    "CLASS_WEIGHT = ['balanced']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of experiments.\n",
    "n_experiments = 20\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random_states = np.random.randint(1000, size=n_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Hash out the estimators that are excluded from this experiment.\n",
    "estimators = {\n",
    "    # NB: Reports colinear variables.\n",
    "    'lda': LinearDiscriminantAnalysis,\n",
    "    'logreg': LogisticRegression,\n",
    "    # NB: warnings.warn('Y residual constant at iteration %s' % k)\n",
    "    'pls': PLSRegression,\n",
    "    #'adaboost': AdaBoostClassifier,\n",
    "    'gnb': GaussianNB,\n",
    "    'svc': SVC,\n",
    "}\n",
    "# C2 = PLS + GNB\n",
    "# C1 = rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_l1 = LogisticRegression(\n",
    "    penalty='l1', class_weight='balanced', random_state=SEED,\n",
    "    solver='liblinear'\n",
    ")\n",
    "logreg_l2 = LogisticRegression(\n",
    "    penalty='l2', class_weight='balanced', random_state=SEED,\n",
    "    solver='liblinear'\n",
    ")\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=50, class_weight='balanced', random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'lda': {\n",
    "        # NOTE: n_components determined in model selection\n",
    "        'n_components': [None], 'tol': TOL, 'priors': [PFS_PRIORS],\n",
    "    },\n",
    "    'logreg': {\n",
    "        'C': C, 'solver': ['liblinear'], 'penalty': PENALTY,\n",
    "        'class_weight': CLASS_WEIGHT, 'max_iter': MAX_ITER\n",
    "    },\n",
    "    'pls': {\n",
    "        # NOTE: n_components determined in model selection\n",
    "        'n_components': [None], 'tol': TOL,\n",
    "    },\n",
    "    'adaboost': {\n",
    "        'base_estimator': [logreg_l2],\n",
    "        'learning_rate': LEARNINGR_RATE, 'n_estimators': N_ESTIMATORS,\n",
    "    },\n",
    "    'svc': {\n",
    "        'kernel': ['rbf'], 'C': C,\n",
    "        'gamma': [0.0001, 0.001, 0.01, 0.1, 0.3, 0.7, 1],\n",
    "        'cache_size': [20, 100, 300, 500], 'degree': [2, 3],\n",
    "        'class_weight': CLASS_WEIGHT\n",
    "    },\n",
    "    'lin_svc': {\n",
    "        'C': C, 'class_weight': CLASS_WEIGHT, 'penalty': PENALTY,\n",
    "        'dual': [False], 'tol': TOL,\n",
    "    },\n",
    "    'gnb': {'priors': [PFS_PRIORS]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectors = {\n",
    "    # Wrapper methods:\n",
    "    'ff_logregl1': feature_selection.forward_floating,\n",
    "    'ff_logregl2': feature_selection.forward_floating,\n",
    "    'rf_permut_imp': feature_selection.permutation_importance,\n",
    "    # Filter methods:\n",
    "    'var_thresh': feature_selection.variance_threshold,\n",
    "    'relieff': feature_selection.relieff,\n",
    "    'mutual_info': feature_selection.mutual_info,\n",
    "}\n",
    "selector_params = {\n",
    "    'ff_logregl1': {'model': logreg_l1, 'k': K, 'cv': 2, 'scoring': SCORE},\n",
    "    'ff_logregl2': {'model': logreg_l2, 'k': K, 'cv': 2, 'scoring': SCORE},\n",
    "    'rf_permut_imp': {'model': rf_model, 'thresh': 0.0, 'nreps': 1},\n",
    "    'var_thresh': {'alpha': 0.05},\n",
    "    'relieff': {'k': K, 'n_neighbors': 20},\n",
    "    'mutual_info': {'n_neighbors': 20, 'thresh': 0.05},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_scheme = nested_cross_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_pfs = pd.read_csv(\n",
    "    './../../data/to_analysis/target_pfs.csv', index_col=0\n",
    ")\n",
    "df_y_lrc = pd.read_csv(\n",
    "    './../../data/to_analysis/target_lrc.csv', index_col=0\n",
    ")\n",
    "y_pfs, y_lrc = np.squeeze(df_y_pfs.values), np.squeeze(df_y_lrc.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_feature_dir = './../../data/to_analysis'\n",
    "ref_results_pfs_dir = './../../data/outputs/model_comparison_pfs'\n",
    "ref_results_lrc_dir = './../../data/outputs/model_comparison_lrc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirnames = utils.listdir(ref_feature_dir)\n",
    "dirnames[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select subsets of filters to run with ensuring completed runs\n",
    "# per interesting image types (see Alise work for selecting)\n",
    "for dirname in dirnames:\n",
    "\n",
    "    file_paths = ioutil.relative_paths(\n",
    "        os.path.join(ref_feature_dir, dirname), target_format='.csv'\n",
    "    )\n",
    "    for path_to_file in file_paths:\n",
    "\n",
    "        X = pd.read_csv(path_to_file, index_col=0).values\n",
    "\n",
    "        # path_pfs_results = TODO: where to save results\n",
    "\n",
    "        # NOTE: PFS\n",
    "        pfs_results = model_comparison(\n",
    "            selection_scheme, X, y_pfs, estimators, hparams, selectors,\n",
    "            selector_params, random_states, CV, score_func=SCORE\n",
    "        )\n",
    "        # Write results for each analyzed data set of current filter and\n",
    "        # discr combo.\n",
    "        ioutil.write_final_results(path_pfs_results, pfs_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
